\documentclass{article}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amscd}
\usepackage{mathrsfs}
\usepackage{bm}
\usepackage{url,hyperref}

\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}[thm]{Corollary}
\newtheorem{lem}[thm]{Lemma}
\newtheorem{prop}[thm]{Proposition}
\newtheorem{conj}[thm]{Conjecture}
\newtheorem{assumption}[thm]{Assumption}
\theoremstyle{definition}
\newtheorem{defn}[thm]{Definition}%[section]
\newtheorem{example}[thm]{Example}
\newtheorem{remark}[thm]{Remark}
\newtheorem{algorithm}[thm]{Algorithm}

\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\A}{\mathbb{A}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\Prob}{{\rm Prob}}
\newcommand{\pa}{{\rm pa}}
\newcommand{\nd}{{\rm nd}}
\def\ci{\perp\!\!\!\perp}

\title{Graphical models}
\author{Luis David Garcia-Puente, \\Sonja Petrovi\'c, Seth Sullivant}
%\date{}
\date{\today}

\begin{document}
\maketitle
\begin{abstract}
{\bf The abstract is not to exceed 150 words.}

The \emph{Macaulay2} package \emph{GraphicalModels} contains implementations of...

{\bf Good example of a recent paper:}\\ \url{http://j-sag.org/Volume4/jsag-1-2012.pdf}
\end{abstract}


\section{Graphical models}
A graphical model is a statistical model associated to a graph,
where the nodes of the graph represent random variables and the
edges in the graph encode relationships between the random variables.
Graphical models are an important class of statistical models used
in many applications (see standard textbooks \cite{Lauritzen, Whitaker})
because of their ability to model complex interactions between
many random variables, by specifying
interactions using only local information about connectivity
between the vertices in a graph.

There are two natural ways to specify a graphical model, through 
either conditional independence statements specified by the graph
or via a parametric representation (sometimes called a ``factorization'').
A fundamental question about graphical models is: For what
graphs the parametric representation is equivalent to the
representation by conditional independence statements?
Every distribution which factors according to the graph
satisfies the conditional independence statements implied by the 
graph, so one can ask:  Which distributions satisfy the conditional
independence statements implied by the graph, but do not factor?

Once we specify the types of random variables under consideration
(e.g. discrete random variables or Gaussian random variables) it
is possible to address the questions in the preceding paragraph
using (computational) algebraic geometry.  Indeed, in these cases,
the set of all probability distributions satisfying a family of 
conditional independence constraints is a semialgebraic set.
For discrete random variables, that semialgebraic set is a subset
of the probability simplex, and can be represented by a certain
homogeneous ideal generated by quadrics.  For Gaussian random variables,
this set of distribution corresponds to a semialgebraic subset
of the cone of positive definite matrices.  Similarly,
the parametrized family of probability distributions also
is a semialgebraic set (of the probability simplex for discrete
random variables, and of the cone of positive definite matrices
for Gaussian random variables).  This algebraic perspective
has been studied by many authors \cite{}, and the book \cite{DSS}
has many details.

The Macaulay 2 graphical models package allows the user to compute
the ideals of conditional independence statements for any collection
of conditional independence statements for discrete or Gaussian
random variables.  It also can compute the vanishing ideal of 
a graphical model in these cases.  A number of auxiliary functions
are useful for doing further analyses of graphical models.

To be explicit, consider the directed acyclic graph $G$ with  five
vertices $\{a,b,c,d,e\}$ and edge
set $\{a \to d, b \to d, c \to d, c \to e, d \to e\}$.
The following commands computes the associated conditional
independence ideal for the set of global Markov statements,
$CI_{{\rm global}(G)}$ and 
the vanishing ideal of the gaussian graphical model $I_{G}$.

\begin{verbatim}
Macaulay2, version 1.4

i1 : loadPackage "GraphicalModels";
i2 : G = digraph{{a,{d}},{b,{d}},{c,{d,e}},{d,{e}}} 
o2 = Digraph{a => set {d}   }
             b => set {d}
             c => set {d, e}
             d => set {e}
             e => set {}
i3 : R = gaussianRing G
o3 : PolynomialRing
i11 : vars R
o11 = | s_(a,a) s_(a,b) s_(a,c) s_(a,d) s_(a,e) s_(b,b) s_(b,c) s_(b,d) s_(b,e) s_(c,c) s_(c,d) s_(c,e) s_(d,d) s_(d,e) s_(e,e) |
i4 : I = conditionalIndependenceIdeal(R,globalMarkov(G));
i5 : J = gaussianVanishingIdeal(R);
\end{verbatim}
The graphical models package uses the graphs package and 
and a number of fundamental constructs and relationships 
associated with graphs.  First we create a polynomial ring
for carrying out the computations, which contains the entries of
the covariance matrix $\Sigma$ of a jointly normal random vector
as its indeterminates.  The ring encodes information about the
graph, so many functions in the graphical models package use 
use only the ring as input.

For directed acyclic graphs it is known that 
$V(CI_{{\rm global}(G)}) \cap PD_{m}  =  
V(I_{G}) \cap PD_{m}$,
in particular, the set of positive definite matrices
satisfying the conditional independence constraints, equals the
the set of covariance matrices in the image of the parametrization.
Unfortunately, this does not imply that $CI_{{\rm global}(G)} 
=I_{G}$.  In the case of Gaussian random variables, a larger ideal,
the trek ideal $T_{G}$, generated by all subdeterminants of the 
covariance matrix that vanish on the model, and satisfying
$CI_{{\rm global}(G)} \subseteq T_{G} \subseteq
I_{G}$ is sometimes equal to $I_{G}$, which happens for our
graph of interest $G$ in this case.

\begin{verbatim}
i6 : isSubset(I,J)
o6 = true
i7 : I == J
o7 = false
i8 : K = trekIdeal(R,G);
i9 : J == K
o9 = true
\end{verbatim}

Similar computations can also be performed for graphical models
with discrete random variables,
and with other graph families.  The mathematical explanation of
these graphical models and their associated ideals
are explained in the remaining sections.


\section{Computing conditional independence ideals}

\begin{itemize}
\item What do they mean, in general? 
\item  families of CI statements associated to graphs
\item trek separation
\end{itemize}

(This kinda depends on details in the definition of CI in previous section.)
In the case of $n$ discrete random variables, the conditional independence ideal of a set of statements consists of all polynomial relations on the joint probabilities that hold under the given conditional independence statements.  The ideal lives in the polynomial ring whose indeterminates are joint probabilities indexed by the states of the $n$ random variables. This ring is created by {\tt markovRing}.
Let's consider a very simple example. The statement $1\ci 2 | 3$ for three binary random variables gives rise to the following:

%i32 : statements = {{{1,2},{3},{4}}, {{1},{3},{}}}; 
%\small{
\begin{verbatim}
i56 : s = {{{1},{2},{3}}};  --statement is: {1} independent of {2} given {3}
i58 : R=markovRing(2,2,2) 
o58 : PolynomialRing
i6 : gens R --states of three binary random variables are represented by indices
o6 = {p     , p     , p     , p     , p     , p     , p     , p     }
       1,1,1   1,1,2   1,2,1   1,2,2   2,1,1   2,1,2   2,2,1   2,2,2
i74 : I = conditionalIndependenceIdeal(R,s)

o74 = ideal (- p     p      + p     p     , - p     p      + p     p     )
                1,2,1 2,1,1    1,1,1 2,2,1     1,2,2 2,1,2    1,1,2 2,2,2
\end{verbatim}
%}
In general, $I$ is the ideal of minors of a set of matrices: 
%\small{
\begin{verbatim}
i75 : markovMatrices (R,s)
o75 = {| p_(1,1,1) p_(1,2,1) |, | p_(1,1,2) p_(1,2,2) |}
       | p_(2,1,1) p_(2,2,1) |  | p_(2,1,2) p_(2,2,2) |
\end{verbatim}
%}
If the $1\ci 2 | 3$  indeed holds, the minors all vanish. 


For a given graphical model, there are families of CI statements that always hold. 

...
Given an undirected graph $G$, pairwise Markov statements are statements of the form $v \ci w | \textit{all other vertices}$ for each pair of non-adjacent vertices $v, w$ of $G$. 
%\small{
\begin{verbatim}
i81 : G = graph({{a,b},{b,c},{b,d}}); 
i82 : pairMarkov G
o82 = {{{a}, {c}, {b, d}}, {{a}, {d}, {b, c}}, {{c}, {d}, {b, a}}}
\end{verbatim}
%}

Let's start over. I think this can be the main example in this section. 

\begin{verbatim}
i101 : G = graph({{a,b},{b,c}})
o101 = Graph{a => set {b}   }
             b => set {a, c}
             c => set {b}
i7 : st=pairMarkov G
o7 = {{{a}, {c}, {b}}}
i8 : R=gaussianRing G
o8 : PolynomialRing
i9 : conditionalIndependenceIdeal(R,st)
o9 = ideal(s   s    - s   s   )
            a,c b,b    a,b b,c
i10 : gaussianMatrices (R,st)
o10 = {| s_(a,c) s_(a,b) |}
       | s_(b,c) s_(b,b) |
\end{verbatim}


\section{Computing the vanishing ideal of a model}

The package GraphicalModels has the capability of computing the vanishing ideal
of  a \emph{discrete Bayesian network} (discrete graphical model on a directed
graph) and also of a Gaussian graphical model on a directed, undirected, or  mixed
graph (a graph with directed, and bidirected edges). 

The method
\textbf{discreteVanishingIdeal} implements this capability for discrete Bayesian
networks. A Bayesian network $G$ on $n$ discrete random variables 
is defined parametrically by the
\emph{recursive factorization} of the joint probability  distribution
\[p(X) = \prod_{v} p(X_{v} | X_{\pa v},\]
where the product runs over all vertices $v$ of $G$ and $\pa v$ is the set of
parents of $v$. 
The implementation of this method does not compute the kernel of the
corresponding ring map. Instead, the vanishing ideal is
computed recursively using the factorization 
\[p(X_{1},\dots, X_{n}) = p(X_{1},\dots, X_{n})\cdot p(X_{n} | \pa X_{n}).\]
%At the level of ideals the previous factorization produces the equality
%\[I_{G} = \]

\begin{verbatim}
i3 : G = digraph {{1,{3}}, {2,{3}},{3,{4}},{4,{}}};
i4 : R = markovRing (2,2,2,2);
i8 : I = discreteVanishingIdeal (R,G) / print

\end{verbatim}


\begin{itemize}
\item from parametric representation
\item how does it compare to CI ideal
\item primary decomp.
\end{itemize}




\section{Technical discussion (?) }
This package requires Graphs.m2, as a consequence it can do
computations with graphs whose vertices are not necessarily labeled by
integers. 


\section*{Acknowledgements} {\bf TO DO: -- other authors of the package!....} -- Dan Grayson and Amelia Taylor.




\begin{thebibliography}{20}

\bibitem{theRpackage!}
Gabriel C. G. de Abreu, Rodrigo Labouriau, David Edwards, High-dimensional Graphical Model Search with gRapHD R Package, \href{http://arxiv.org/abs/0909.1234}{arXiv:0909.1234v4}
{\bf CITE ME!!!}

\bibitem{DSS} 
M.~Drton, B.~Sturmfels and S.~Sullivant, (2009) \emph{Lectures on Algebraic Statistics}, Birkhauser 

\bibitem{MortonSturm}
I. Onur Filiz, Xin Guo, Jason Morton, Bernd Sturmfels, Graphical models for correlated defaults, \href{http://arxiv.org/abs/0809.1393}{arXiv:0809.1393v1}
{\bf CITE ME!!!}

\bibitem{GSS} L.~D.~Garcia, M.~Stillman and B.~Sturmfels: Algebraic geometry of Bayesian networks, {\em J. Symbolic Comput.}
  {\bf 39} (2005) 331--355.
  
\bibitem{GeigerMeekSturm}
Dan Geiger, Christopher Meek, Bernd Sturmfels, On the toric algebra of graphical models, \href{http://arxiv.org/abs/math/0608054}{arXiv:math/0608054v1}
{\bf CITE ME!!!}

\bibitem{HaraTakemura}
Hisayuki Hara, Satoshi Aoki, Akimichi Takemura, Minimal and minimal invariant Markov bases of decomposable models for contingency tables, Bernoulli 2010, Vol. 16, No. 1, 208-233  (preprint FOR OUR REFERENCE: \href{http://arxiv.org/abs/math/0701429}{arXiv:math/0701429v3})
{\bf CITE ME?}

\bibitem{Lauritzen}
S.~Lauritzen,  (1996) \emph{Graphical models}, Oxford University Press

\bibitem{Elena}
E.~Stanghellini, B.~Vantaggi, On the identification of discrete graphical models with hidden nodes, \href{http://arxiv.org/abs/1009.4279}{	arXiv:1009.4279v1}
{\bf DO WE NEED THIS REFERENCE?}

\bibitem{S} S.~Sullivant: Algebraic geometry of Gaussian Bayesian
  networks, {\em Adv. in Appl. Math.} {\bf 40} (2008) 482--513.

\bibitem{STD}
S.~Sullivant, K.~Talaska, and J.~Draisma: Trek separation for Gaussian
graphical models, {\em Ann. Statist.} {\bf 38} (2010) 1665--1685. 

\bibitem{GPSS} L.~D.~Garcia-Puente, S.~Spielvogel and S.~Sullivant: Identifying
causal effects with computer algebra, to appear in {\em Proceedings of the 26th
Conference of Uncertainty in Artificial Intelligence}.

\bibitem{Whitaker}  Whitaker.  Graphcial Models in Applied Multivariate Statistics.

\end{thebibliography}
\end{document}


